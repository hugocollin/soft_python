{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets        # Importation de la bibliothÃ¨que ipywidgets, afin de crÃ©er des composants interactifs\n",
    "from IPython.display import display # Importation de la bibliothÃ¨que IPython.display, afin d'afficher des objets Ã  l'intÃ©rieur d'une cellule d'un notebook Python\n",
    "\n",
    "# Widget texte pour saisir le mot-clÃ© de recherche\n",
    "recherche_widget = widgets.Text(\n",
    "    value='Space',    # Valeur par dÃ©faut du texte\n",
    "    description='ðŸ”' # Description affichÃ©e Ã  cÃ´tÃ© du widget\n",
    ")\n",
    "\n",
    "# Widget curseur pour sÃ©lectionner le nombre d'articles Ã  extraire\n",
    "nombre_articles_widget = widgets.IntSlider(\n",
    "    value=100,                                     # Valeur par dÃ©faut du curseur\n",
    "    min=1,                                         # Valeur minimale autorisÃ©e\n",
    "    max=1000,                                      # Valeur maximale autorisÃ©e\n",
    "    step=1,                                        # IncrÃ©ments du curseur\n",
    "    description='Nombre d\\'articles Ã  extraire :', # Description affichÃ©e Ã  cÃ´tÃ© du widget\n",
    "    style={'description_width': 'initial'},        # Style pour la largeur de la description\n",
    "    layout={'width': '30%'}                        # Ajustement de la largeur du curseur\n",
    ")\n",
    "\n",
    "# Fonction pour rÃ©cupÃ©rer les valeurs des widgets\n",
    "def execute_recherche(change):\n",
    "    global recherche, nombre_articles\n",
    "    recherche = recherche_widget.value              # RÃ©cupÃ©ration du texte saisi dans la barre de recherche\n",
    "    nombre_articles = nombre_articles_widget.value  # RÃ©cupÃ©ration du nombre d'articles Ã  extraire\n",
    "\n",
    "# Widget bouton pour lancer la recherche\n",
    "bouton_recherche = widgets.Button(description=\"Rechercher\") # CrÃ©ation d'un widget bouton avec le texte \"Rechercher\" affichÃ© dessus\n",
    "bouton_recherche.on_click(execute_recherche)                # Association d'une fonction spÃ©cifique Ã  exÃ©cuter lorsque le bouton est cliquÃ©\n",
    "\n",
    "# Affichage des widgets et du bouton\n",
    "display(widgets.VBox([recherche_widget, nombre_articles_widget, widgets.HBox([widgets.Label(''), bouton_recherche])], layout={'align_items': 'center'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Document import RedditDocument, ArxivDocument # Importation de la classe RedditDocument et ArxivDocument depuis le module Document\n",
    "from Author import Author                          # Importation de la classe Author depuis le module Author\n",
    "from Corpus import CorpusSingleton                 # Importation de la classe Corpus depuis le module Corpus\n",
    "\n",
    "import praw           # Importation la bibliothÃ¨que praw pour accÃ©der Ã  l'API de Reddit\n",
    "import urllib.request # Importation la bibliothÃ¨que urllib pour effectuer des requÃªtes HTTP \n",
    "import xmltodict      # Importation de la bibliothÃ¨que xmltodict pour analyser des donnÃ©es XML\n",
    "import datetime       # Importation de la bibliothÃ¨que datetime pour manipuler des dates et des heures\n",
    "import pickle         # Importation de la bibliothÃ¨que pickle pour convertir un objet en un format binaire pouvant Ãªtre enregistrÃ© dans un fichier ou transmis sur un rÃ©seau\n",
    "\n",
    "# Initilisation de variables globales\n",
    "recherche_str = str(recherche)             # Conversion de la variable en chaine de caractÃ¨res\n",
    "nombre_articles_int = int(nombre_articles) # Conversion de la variable en entier\n",
    "\n",
    "\n",
    "textes_reddit = []# Initialisation de la liste de textes Reddit\n",
    "textes_arxiv = [] # Initialisation de la liste de textes ArXiv\n",
    "\n",
    "textes_bruts_reddit = []# Initialisation de la liste de textes bruts Reddit\n",
    "textes_bruts_arxiv = [] # Initialisation de la liste de textes bruts ArXiv\n",
    "\n",
    "\n",
    "# ParamÃ¨tres de recherche de Reddit\n",
    "reddit = praw.Reddit(client_id='-GD1SJ96QztEIjktZ0o6nQ', client_secret='GinKmTjo2ggKztu0bwSb6mlXHX57Pw', user_agent='FAC') # Connexion Ã  Reddit en utilisant les identifiants\n",
    "subr = reddit.subreddit(recherche_str).hot(limit=nombre_articles_int)                                                      # Recherche des documents correspondants au topic de la recherche\n",
    "\n",
    "if subr:\n",
    "    # RÃ©cupÃ©ration des posts Reddit\n",
    "    for post in subr:\n",
    "        texte = post.title                    # Extraction du contenu textuel\n",
    "        texte = texte.replace(\"\\n\", \" \")      # Remplacement des retours Ã  la ligne par des espaces dans le titre\n",
    "        textes_reddit.append(texte)                  # Ajout du texte Ã  la liste de textes\n",
    "        textes_bruts_reddit.append((\"Reddit\", post)) # Ajout du texte brut Ã  la liste de textes bruts\n",
    "else:\n",
    "    print(\"Aucun document trouvÃ© avec Reddit\")\n",
    "\n",
    "\n",
    "# ParamÃ¨tres de recherche de Arxiv\n",
    "url = 'http://export.arxiv.org/api/query?search_query=all:' + recherche_str + '&start=0&max_results=' + str(nombre_articles_int) # Recherche des documents correspondants au topic de la recherche\n",
    "data = urllib.request.urlopen(url)                                                                                                 # Ouverture de la connexion HTTP\n",
    "data = xmltodict.parse(data.read().decode('utf-8'))                                                                                # DÃ©code et analyse les donnÃ©es au format XML\n",
    "\n",
    "# verifier si le nombre d'articles trouvÃ©s est suffisant\n",
    "if 'entry' in data['feed'] and data['feed']['entry']:\n",
    "    # RÃ©cupÃ©ration des posts Arxiv\n",
    "    for document in data['feed']['entry']:\n",
    "        texte = document['title']+ \". \" + document['summary'] # Extraction du contenu textuel\n",
    "        texte = texte.replace(\"\\n\", \" \")                      # Remplacement des retours Ã  la ligne par des espaces dans le titre\n",
    "        textes_arxiv.append(texte)                                  # Ajout du texte Ã  la liste de textes\n",
    "        textes_bruts_arxiv.append((\"ArXiv\", document))              # Ajout du texte brut Ã  la liste de textes bruts\n",
    "else:\n",
    "    print(\"Aucun document trouvÃ© avec ArXiv\")\n",
    "\n",
    "# Suppression des textes trop courts\n",
    "textes_reddit = [texte for texte in textes_reddit if len(texte) >= 100]\n",
    "textes_arxiv = [texte for texte in textes_arxiv if len(texte) >= 100]\n",
    "\n",
    "textes = []       # Initialisation de la liste de textes\n",
    "textes_bruts = [] # Initialisation de la liste de textes bruts\n",
    "\n",
    "index_reddit = 0 # Initialisation de l'index de parcour sur les textes Reddit\n",
    "index_arxiv = 0  # Initialisation de l'index de parcour sur les textes ArXiv\n",
    "\n",
    "# On ajoute le nombre d'elements necessaires a la liste de textes\n",
    "# On s'arrete si on a parcouru tous les textes Reddit et ArXiv ou si on a atteint le nombre d'articles demandes\n",
    "while len(textes) < nombre_articles_int and (index_reddit < len(textes_reddit) or index_arxiv < len(textes_arxiv)):\n",
    "    # On verifie qu'il y ait encore des textes Reddit\n",
    "    if index_reddit < len(textes_reddit):\n",
    "        textes.append(textes_reddit[index_reddit])\n",
    "        textes_bruts.append(textes_bruts_reddit[index_reddit])\n",
    "        index_reddit += 1\n",
    "    # On verifie qu'il y ait encore des textes ArXiv\n",
    "    if index_arxiv < len(textes_arxiv):\n",
    "        textes.append(textes_arxiv[index_arxiv])\n",
    "        textes_bruts.append(textes_bruts_arxiv[index_arxiv])\n",
    "        index_arxiv += 1\n",
    "\n",
    "# Traitements sur les textes\n",
    "for i, texte in enumerate(textes): # Affichage des caractÃ©ristiques de chaque texte\n",
    "    print(f\"Document {i} :\\t# Nombre de caractÃ¨res : {len(texte)}\\t# Nombre de mots : {len(texte.split(' '))}\\t# Nombre de phrases : {len(texte.split('.'))}\")\n",
    "\n",
    "\n",
    "textes = \" \".join(textes) # Combination des Ã©lÃ©ments de la liste textes en une chaÃ®ne de caractÃ¨res, en les sÃ©parant par des espaces\n",
    "\n",
    "collection = [] # Initialisation d'une liste vide pour contenir les documents\n",
    "\n",
    "for nature, texte in textes_bruts:\n",
    "    # Si la nature du document est \"Reddit\"\n",
    "    if nature == \"Reddit\":\n",
    "        titre = texte.title.replace(\"\\n\", '')                                       # Remplacement des retours Ã  la ligne par des espaces dans le titre\n",
    "        auteur = str(texte.author)                                                  # Convertion de l'auteur en chaÃ®ne de caractÃ¨res\n",
    "        date = datetime.datetime.fromtimestamp(texte.created).strftime(\"%Y/%m/%d\")  # Formatage de la date en annÃ©e/mois/jour\n",
    "        url = \"https://www.reddit.com/\"+ texte.permalink                            # CrÃ©ation de l'URL du texte\n",
    "        texte = texte.selftext.replace(\"\\n\", \"\")                                    # Remplace des retours Ã  la ligne par des espaces dans le texte\n",
    "        post.comments.replace_more(limit=None)                                      # Chargement de tous les commentaires du post\n",
    "        nb_commentaires = len(post.comments.list())                                 # Obtention du nombre total de commentaires\n",
    "        document = RedditDocument(titre, auteur, date, url, texte, nb_commentaires) # CrÃ©ation d'un document Ã  partir des donnÃ©es rÃ©cupÃ©rÃ©es\n",
    "        print(document)\n",
    "        collection.append(document)                                                 # Ajout du document Ã  la liste collection\n",
    "\n",
    "    # Sinon, si la nature du document est \"ArXiv\"\n",
    "    elif nature == \"ArXiv\": \n",
    "        titre = texte[\"title\"].replace('\\n', '')                                                         # Remplacement des retours Ã  la ligne par des espaces dans le titre\n",
    "        try:\n",
    "            auteurs = ([a.get(\"name\", \"\") for a in texte.get(\"author\", []) if isinstance(a, dict)])      # CrÃ©ation d'une liste d'auteurs\n",
    "        except:\n",
    "            auteurs = texte.get(\"author\", {}).get(\"name\", \"\")                                            # Si l'auteur est seul, il n'y a pas besoin de liste\n",
    "        summary = texte[\"summary\"].replace(\"\\n\", \"\")                                                     # Remplace des retours Ã  la ligne par des espaces dans le texte\n",
    "        date = datetime.datetime.strptime(texte[\"published\"], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y/%m/%d\") # Formatage de la date en annÃ©e/mois/jour\n",
    "        document = ArxivDocument(titre, auteurs, date, texte[\"id\"], summary)                             # CrÃ©ation d'un document Ã  partir des donnÃ©es rÃ©cupÃ©rÃ©es\n",
    "        print(document)\n",
    "        collection.append(document)                                                                      # Ajout du document Ã  la liste collection\n",
    "\n",
    "# CrÃ©ation de l'index de documents\n",
    "id2doc = {}\n",
    "for i, doc in enumerate(collection):\n",
    "    id2doc[i] = doc.titre\n",
    "\n",
    "auteurs = {}\n",
    "aut2id = {} \n",
    "nombre_auteurs = 0\n",
    "\n",
    "# CrÃ©ation de la liste+index des Auteurs\n",
    "for texte in collection:\n",
    "    if texte.auteur not in aut2id:\n",
    "        nombre_auteurs += 1\n",
    "        auteurs[nombre_auteurs] = Author(texte.auteur)\n",
    "        aut2id[doc.auteur] = nombre_auteurs\n",
    "\n",
    "    auteurs[aut2id[doc.auteur]].add(texte.texte)\n",
    "\n",
    "# Utilisation du Singleton pour obtenir l'instance unique de Corpus\n",
    "corpus_singleton = CorpusSingleton()\n",
    "corpus = corpus_singleton.get_corpus()\n",
    "\n",
    "# Nettoyage du corpus puis remplissage\n",
    "corpus.clear()\n",
    "for doc in collection:\n",
    "    corpus.add(doc)\n",
    "\n",
    "# Ouverture d'un fichier, puis Ã©criture avec pickle\n",
    "with open(\"corpus.pkl\", \"wb\") as f:\n",
    "    pickle.dump(corpus, f)\n",
    "\n",
    "# Supression de la variable corpus\n",
    "del corpus\n",
    "\n",
    "# Ouverture du fichier, puis lecture avec pickle\n",
    "with open(\"corpus.pkl\", \"rb\") as f:\n",
    "    corpus = pickle.load(f)\n",
    "\n",
    "# Affichage du corpus\n",
    "corpus.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProgrammationPython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
